{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import MyOwnDataloader\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total    : 12636.061696\n",
      "free     : 5004.132352\n",
      "used     : 7631.929344\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "\n",
    "from pynvml import *\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total/1000000}')\n",
    "print(f'free     : {info.free/1000000}')\n",
    "print(f'used     : {info.used/1000000}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    custom_transforms = []\n",
    "    custom_transforms.append(torchvision.transforms.Resize((256, 256)))\n",
    "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
    "    custom_transforms.append(torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
    "    return torchvision.transforms.Compose(custom_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/media/gamedisk/COCO_dataset/'\n",
    "val='val2017'\n",
    "train = 'train2017'\n",
    "\n",
    "val_annFile='{}/annotations/instances_{}.json'.format(dataDir,val)\n",
    "train_annFile='{}/annotations/instances_{}.json'.format(dataDir,train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=21.14s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_coco =  torchvision.datasets.CocoDetection('/media/gamedisk/COCO_dataset/images/train2017', train_annFile, transforms= get_transform())\n",
    "train_dl =  torch.utils.data.DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/datasets/coco.py\", line 52, in __getitem__\n    image, target = self.transforms(image, target)\nTypeError: __call__() takes 2 positional arguments but 3 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/work_in_progress/non_snn_final _model.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/work_in_progress/non_snn_final%20_model.ipynb#ch0000016?line=0'>1</a>\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_dl))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1221'>1222</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1222'>1223</a>\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1223'>1224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1247'>1248</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1248'>1249</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1249'>1250</a>\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1250'>1251</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=452'>453</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=453'>454</a>\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=454'>455</a>\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=455'>456</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=456'>457</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/datasets/coco.py\", line 52, in __getitem__\n    image, target = self.transforms(image, target)\nTypeError: __call__() takes 2 positional arguments but 3 were given\n"
     ]
    }
   ],
   "source": [
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/datasets/coco.py\", line 52, in __getitem__\n    image, target = self.transforms(image, target)\nTypeError: __call__() takes 2 positional arguments but 3 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/work_in_progress/non_snn_final _model.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/work_in_progress/non_snn_final%20_model.ipynb#ch0000015?line=0'>1</a>\u001b[0m data, targets \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_dl))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/work_in_progress/non_snn_final%20_model.ipynb#ch0000015?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/work_in_progress/non_snn_final%20_model.ipynb#ch0000015?line=2'>3</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1221'>1222</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1222'>1223</a>\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1223'>1224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1247'>1248</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1248'>1249</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1249'>1250</a>\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1250'>1251</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=452'>453</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=453'>454</a>\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=454'>455</a>\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=455'>456</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_utils.py?line=456'>457</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/datasets/coco.py\", line 52, in __getitem__\n    image, target = self.transforms(image, target)\nTypeError: __call__() takes 2 positional arguments but 3 were given\n"
     ]
    }
   ],
   "source": [
    "data, targets = next(iter(train_dl))\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=9.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=9.60s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataDir='/media/gamedisk/COCO_dataset/'\n",
    "val='val2017'\n",
    "train = 'train2017'\n",
    "\n",
    "val_annFile='{}/annotations/instances_{}.json'.format(dataDir,val)\n",
    "train_annFile='{}/annotations/instances_{}.json'.format(dataDir,train) \n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "classes = {\n",
    "    \"cat\": 1,\n",
    "    \"dog\": 2\n",
    "}\n",
    "\n",
    "\n",
    "coco = COCO(val_annFile)\n",
    "val_loader = MyOwnDataloader(dataDir = dataDir, dataType = val,\n",
    "                     annFile = val_annFile, classes = classes, train_batch_size=batch_size)\n",
    "valid_dl = val_loader.concat_datasets()\n",
    "\n",
    "\n",
    "coco = COCO(train_annFile)\n",
    "train_loader = MyOwnDataloader(dataDir = dataDir, dataType = train,\n",
    "                     annFile = train_annFile, classes = classes, train_batch_size=batch_size)\n",
    "train_dl = val_loader.concat_datasets()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        # CNNs for rgb images\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5)\n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=5)\n",
    "        self.conv5 = nn.Conv2d(in_channels=48, out_channels=192, kernel_size=5)\n",
    "\n",
    "\n",
    "        # Connecting CNN outputs with Fully Connected layers for classification\n",
    "        self.class_fc1 = nn.Linear(in_features=1728, out_features=240)\n",
    "        self.class_fc2 = nn.Linear(in_features=240, out_features=120)\n",
    "        self.class_out = nn.Linear(in_features=120, out_features=2)\n",
    "\n",
    "        # Connecting CNN outputs with Fully Connected layers for bounding box\n",
    "        self.box_fc1 = nn.Linear(in_features=1728, out_features=240)\n",
    "        self.box_fc2 = nn.Linear(in_features=240, out_features=120)\n",
    "        self.box_out = nn.Linear(in_features=120, out_features=4)\n",
    "\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = self.conv3(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = self.conv4(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = self.conv5(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.avg_pool2d(t, kernel_size=4, stride=2)\n",
    "\n",
    "        t = torch.flatten(t,start_dim=1)\n",
    "        \n",
    "        # t = t.T\n",
    "\n",
    "        class_t = self.class_fc1(t)\n",
    "        class_t = F.relu(class_t)\n",
    "\n",
    "        class_t = self.class_fc2(class_t)\n",
    "        class_t = F.relu(class_t)\n",
    "\n",
    "        class_t = F.softmax(self.class_out(class_t),dim=1)\n",
    "\n",
    "        box_t = self.box_fc1(t)\n",
    "        box_t = F.relu(box_t)\n",
    "\n",
    "        box_t = self.box_fc2(box_t)\n",
    "        box_t = F.relu(box_t)\n",
    "\n",
    "        box_t = self.box_out(box_t)\n",
    "        box_t = F.sigmoid(box_t)\n",
    "\n",
    "        return [class_t,box_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return torch.round(preds).argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    # Defining the optimizer\n",
    "    optimizer = optim.SGD(model.parameters(),lr = 0.1)\n",
    "    num_of_epochs = 30\n",
    "    epochs = []\n",
    "    losses = []\n",
    "    # Creating a directory for storing models\n",
    "\n",
    "    for epoch in range(num_of_epochs):\n",
    "        tot_loss = 0\n",
    "        tot_correct = 0\n",
    "        train_start = time.time()\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        for batch, (images, annotations) in tqdm(enumerate(train_dl)):\n",
    "\n",
    "        \t# Converting data from cpu to GPU if available to improve speed\n",
    "            imgs = list(img.to(device) for img in images)\n",
    "            neural_images = torch.stack(imgs)\n",
    "            x = neural_images.to(device)\n",
    "            y = annotations\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            z = annotations[0]['boxes']\n",
    "            # z = z.type(torch.LongTensor)\n",
    "            z = z.to(device)\n",
    "            # Sets the gradients of all optimized tensors to zero\n",
    "            optimizer.zero_grad()\n",
    "            [y_pred,z_pred]= model(x)\n",
    "            print(y)\n",
    "            # Compute loss (here CrossEntropyLoss)\n",
    "            class_loss = F.cross_entropy(y_pred, y)\n",
    "            box_loss = F.mse_loss(z_pred[0], z)\n",
    "            (box_loss + class_loss).backward()\n",
    "            # class_loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"Train batch:\", batch+1, \" epoch: \", epoch, \" \",\n",
    "                  (time.time()-train_start)/60, end='\\r')\n",
    "\n",
    "        model.eval()\n",
    "        for batch, (images, annotations) in tqdm(enumerate(valid_dl)):\n",
    "        \t# Converting data from cpu to GPU if available to improve speed\t\n",
    "            imgs = list(img.to(device) for img in images)\n",
    "            neural_images = torch.stack(imgs)\n",
    "            x = neural_images.to(device)\n",
    "            annotations = [{k: v for k, v in t.items()} for t in annotations]\n",
    "            y = annotations[0]['labels'].to(device)\n",
    "            z = annotations[0]['boxes'].to(device)\n",
    "            # Sets the gradients of all optimized tensors to zero\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                [y_pred,z_pred]= model(x)\n",
    "                \n",
    "                # Compute loss (here CrossEntropyLoss)\n",
    "                class_loss = F.cross_entropy(y_pred, y)\n",
    "                box_loss = F.mse_loss(z_pred[0], z)\n",
    "                # Compute loss (here CrossEntropyLoss)\n",
    "\n",
    "            tot_loss += (class_loss.item() + box_loss.item())\n",
    "            tot_correct += get_num_correct(y_pred, y)\n",
    "            print(\"Test batch:\", batch+1, \" epoch: \", epoch, \" \",\n",
    "                  (time.time()-train_start)/60, end='\\r')\n",
    "        epochs.append(epoch)\n",
    "        losses.append(tot_loss)\n",
    "        print(\"Epoch\", epoch, \"Accuracy\", (tot_correct)/2.4, \"loss:\",\n",
    "              tot_loss, \" time: \", (time.time()-train_start)/60, \" mins\")\n",
    "        torch.save(model.state_dict(), \"model_ep\"+str(epoch+1)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv4): Conv2d(24, 48, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv5): Conv2d(48, 192, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (class_fc1): Linear(in_features=1728, out_features=240, bias=True)\n",
       "  (class_fc2): Linear(in_features=240, out_features=120, bias=True)\n",
       "  (class_out): Linear(in_features=120, out_features=2, bias=True)\n",
       "  (box_fc1): Linear(in_features=1728, out_features=240, bias=True)\n",
       "  (box_fc2): Linear(in_features=240, out_features=120, bias=True)\n",
       "  (box_out): Linear(in_features=120, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/non_snn_final _model.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/non_snn_final%20_model.ipynb#ch0000010?line=0'>1</a>\u001b[0m train(model)\n",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/non_snn_final _model.ipynb Cell 8'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/non_snn_final%20_model.ipynb#ch0000009?line=20'>21</a>\u001b[0m x \u001b[39m=\u001b[39m neural_images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/non_snn_final%20_model.ipynb#ch0000009?line=21'>22</a>\u001b[0m y \u001b[39m=\u001b[39m annotations\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/non_snn_final%20_model.ipynb#ch0000009?line=22'>23</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39mLongTensor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/non_snn_final%20_model.ipynb#ch0000009?line=23'>24</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/non_snn_final%20_model.ipynb#ch0000009?line=24'>25</a>\u001b[0m z \u001b[39m=\u001b[39m annotations[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mboxes\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b62d0206b570d77ef1bfa49bb04057592ebbd6080402d9290ba5af22960e1b27"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
