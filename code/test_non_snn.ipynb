{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import MyOwnDataloader\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "bird 0 [16] 55299\n"
     ]
    }
   ],
   "source": [
    "dataDir='/media/gamedisk/COCO_dataset/'\n",
    "val='val2017'\n",
    "train = 'train2017'\n",
    "\n",
    "val_annFile='{}/annotations/instances_{}.json'.format(dataDir,val)\n",
    "train_annFile='{}/annotations/instances_{}.json'.format(dataDir,train) \n",
    "# Batch size\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "\n",
    "classes = {\n",
    "    \"bird\": 0,\n",
    "    \"cat\": 1,\n",
    "    \"dog\": 2,\n",
    "    \"horse\": 3,\n",
    "    \"sheep\": 4,\n",
    "    \"cow\": 5,\n",
    "    \"elephant\": 6,\n",
    "    \"bear\": 7,\n",
    "    \"zebra\": 8,\n",
    "    \"giraffe\": 9\n",
    "}\n",
    "\n",
    "\n",
    "coco = COCO(val_annFile)\n",
    "val_loader = MyOwnDataloader(dataDir = dataDir, dataType = val,\n",
    "                     annFile = val_annFile, classes = classes, train_batch_size=batch_size)\n",
    "data_loader = val_loader.concat_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1/137, Loss: 10.653388977050781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2/137, Loss: 13.098834991455078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3/137, Loss: 47.30316925048828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4/137, Loss: 9.815535545349121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6/137, Loss: 12.52155876159668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:03,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7/137, Loss: 3.575284957885742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:03,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8/137, Loss: 5.781394958496094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:04,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9/137, Loss: 12.71387767791748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:05,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11/137, Loss: 7.662105560302734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:05,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12/137, Loss: 27.923887252807617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:05,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13/137, Loss: 8.684164047241211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:06,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14/137, Loss: 9.958576202392578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:07,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 16/137, Loss: 27.396018981933594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:07,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17/137, Loss: 13.241992950439453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:08,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 18/137, Loss: 15.754155158996582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:08,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 19/137, Loss: 14.33704948425293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:09,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 21/137, Loss: 184458656.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:09,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 22/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:09,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 23/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:10,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 24/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:10,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 26/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:11,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 27/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:11,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 28/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:12,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 29/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:12,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 31/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:13,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 32/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:13,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 33/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:14,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 34/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:14,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 36/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:14,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 37/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:15,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 38/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:15,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 39/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:16,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 41/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:16,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 42/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:17,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 43/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:17,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 44/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [00:18,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 46/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:18,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 47/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:19,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 48/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:19,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 49/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:20,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 51/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [00:20,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 52/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:20,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 53/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [00:21,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 54/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:21,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 56/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [00:22,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 57/137, Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/test_non_snn.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/test_non_snn.ipynb#ch0000001?line=33'>34</a>\u001b[0m imgs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(img\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m imgs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/test_non_snn.ipynb#ch0000001?line=34'>35</a>\u001b[0m annotations \u001b[39m=\u001b[39m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m annotations]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/test_non_snn.ipynb#ch0000001?line=35'>36</a>\u001b[0m loss_dict \u001b[39m=\u001b[39m model(imgs, annotations)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/test_non_snn.ipynb#ch0000001?line=36'>37</a>\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(loss \u001b[39mfor\u001b[39;00m loss \u001b[39min\u001b[39;00m loss_dict\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/test_non_snn.ipynb#ch0000001?line=38'>39</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py:98\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py?line=95'>96</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(features, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m     <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py?line=96'>97</a>\u001b[0m     features \u001b[39m=\u001b[39m OrderedDict([(\u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m, features)])\n\u001b[0;32m---> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py?line=97'>98</a>\u001b[0m proposals, proposal_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrpn(images, features, targets)\n\u001b[1;32m     <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py?line=98'>99</a>\u001b[0m detections, detector_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroi_heads(features, proposals, images\u001b[39m.\u001b[39mimage_sizes, targets)\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py?line=99'>100</a>\u001b[0m detections \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mpostprocess(detections, images\u001b[39m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[39m# type: ignore[operator]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/rpn.py:342\u001b[0m, in \u001b[0;36mRegionProposalNetwork.forward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/rpn.py?line=339'>340</a>\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(features\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/rpn.py?line=340'>341</a>\u001b[0m objectness, pred_bbox_deltas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead(features)\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/rpn.py?line=341'>342</a>\u001b[0m anchors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49manchor_generator(images, features)\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/rpn.py?line=343'>344</a>\u001b[0m num_images \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(anchors)\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/rpn.py?line=344'>345</a>\u001b[0m num_anchors_per_level_shape_tensors \u001b[39m=\u001b[39m [o[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m objectness]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py:122\u001b[0m, in \u001b[0;36mAnchorGenerator.forward\u001b[0;34m(self, image_list, feature_maps)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=119'>120</a>\u001b[0m image_size \u001b[39m=\u001b[39m image_list\u001b[39m.\u001b[39mtensors\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=120'>121</a>\u001b[0m dtype, device \u001b[39m=\u001b[39m feature_maps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype, feature_maps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdevice\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=121'>122</a>\u001b[0m strides \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=122'>123</a>\u001b[0m     [\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=123'>124</a>\u001b[0m         torch\u001b[39m.\u001b[39mtensor(image_size[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m g[\u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64, device\u001b[39m=\u001b[39mdevice),\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=124'>125</a>\u001b[0m         torch\u001b[39m.\u001b[39mtensor(image_size[\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m g[\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64, device\u001b[39m=\u001b[39mdevice),\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=125'>126</a>\u001b[0m     ]\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=126'>127</a>\u001b[0m     \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m grid_sizes\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=127'>128</a>\u001b[0m ]\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=128'>129</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_cell_anchors(dtype, device)\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=129'>130</a>\u001b[0m anchors_over_all_feature_maps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_anchors(grid_sizes, strides)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py:124\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=119'>120</a>\u001b[0m image_size \u001b[39m=\u001b[39m image_list\u001b[39m.\u001b[39mtensors\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=120'>121</a>\u001b[0m dtype, device \u001b[39m=\u001b[39m feature_maps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype, feature_maps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=121'>122</a>\u001b[0m strides \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=122'>123</a>\u001b[0m     [\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=123'>124</a>\u001b[0m         torch\u001b[39m.\u001b[39;49mtensor(image_size[\u001b[39m0\u001b[39;49m] \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m g[\u001b[39m0\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mint64, device\u001b[39m=\u001b[39;49mdevice),\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=124'>125</a>\u001b[0m         torch\u001b[39m.\u001b[39mtensor(image_size[\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m g[\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64, device\u001b[39m=\u001b[39mdevice),\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=125'>126</a>\u001b[0m     ]\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=126'>127</a>\u001b[0m     \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m grid_sizes\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=127'>128</a>\u001b[0m ]\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=128'>129</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_cell_anchors(dtype, device)\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torchvision/models/detection/anchor_utils.py?line=129'>130</a>\u001b[0m anchors_over_all_feature_maps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_anchors(grid_sizes, strides)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "    \n",
    "\n",
    "# 2 classes; Only target class or background\n",
    "\n",
    "num_epochs = 2\n",
    "model = get_model_instance_segmentation(10)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "    \n",
    "# parameters\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "len_dataloader = len(data_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    i = 0 \n",
    "    print(f'epoch # {epoch}')   \n",
    "    for i, (imgs, annotations) in tqdm(enumerate(data_loader)):\n",
    "        i += 1\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        loss_dict = model(imgs, annotations)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i%5:\n",
    "            print(f'Iteration: {i}/{len_dataloader}, Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b62d0206b570d77ef1bfa49bb04057592ebbd6080402d9290ba5af22960e1b27"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
