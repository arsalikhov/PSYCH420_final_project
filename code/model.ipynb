{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import MyOwnDataloader\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total    : 12636.061696\n",
      "free     : 5490.2784\n",
      "used     : 7145.783296\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "\n",
    "from pynvml import *\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total/1000000}')\n",
    "print(f'free     : {info.free/1000000}')\n",
    "print(f'used     : {info.used/1000000}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=11.13s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "dataDir='/media/gamedisk/COCO_dataset/'\n",
    "val='val2017'\n",
    "train = 'train2017'\n",
    "test = 'test2017'\n",
    "\n",
    "val_annFile='{}/annotations/instances_{}.json'.format(dataDir,val)\n",
    "train_annFile='{}/annotations/instances_{}.json'.format(dataDir,train)\n",
    "test_annFile='/media/gamedisk/COCO_dataset/annotations/image_info_test2017.json' \n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "classes = {\n",
    "    \"bird\": 1,\n",
    "    \"cat\": 2,\n",
    "    \"dog\": 3,\n",
    "    \"horse\": 4,\n",
    "    \"sheep\": 5,\n",
    "    \"cow\": 6,\n",
    "    \"elephant\": 7,\n",
    "    \"bear\": 8,\n",
    "    \"zebra\": 9,\n",
    "    \"giraffe\": 10\n",
    "}\n",
    "\n",
    "\n",
    "train_loader = MyOwnDataloader(dataDir = dataDir, dataType = train,\n",
    "                     annFile = train_annFile, classes = classes, train_batch_size=batch_size)\n",
    "train_dl = train_loader.concat_datasets()\n",
    "\n",
    "\n",
    "# test_loader = MyOwnDataloader(dataDir = dataDir, dataType = test,\n",
    "#                      annFile = test_annFile, classes = classes, train_batch_size=batch_size)\n",
    "# test_dl = test_loader.concat_datasets()\n",
    "\n",
    "\n",
    "val_loader = MyOwnDataloader(dataDir = dataDir, dataType = val,\n",
    "                     annFile = val_annFile, classes = classes, train_batch_size=batch_size)\n",
    "valid_dl = val_loader.concat_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "num_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, timesteps: int):\n",
    "        super(Network, self).__init__()\n",
    "        self.timesteps = timesteps\n",
    "        # CNNs for rgb images\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32,\n",
    "                        kernel_size=7,\n",
    "                        padding=3,\n",
    "                        # no bias because it is not bio-plausible (and hard to impl in neuromorphic hardware)\n",
    "                        bias=True,\n",
    "                        dilation=1,\n",
    "                        stride=2)\n",
    "        self.lif1 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64,\n",
    "                               kernel_size=3,\n",
    "                               padding=1,\n",
    "                               # no bias because it is not bio-plausible (and hard to impl in neuromorphic hardware)\n",
    "                               bias=True,\n",
    "                               stride=2)\n",
    "        self.lif2 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                        bias=True,\n",
    "                        stride=2)\n",
    "        self.lif3 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                        # no bias because it is not bio-plausible (and hard to impl in neuromorphic hardware)\n",
    "                        bias=True,\n",
    "                        stride=2)\n",
    "        self.lif4 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 512,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    bias=True,\n",
    "                    stride=2)\n",
    "        self.lif5 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc = nn.Linear(512, out_channels, bias=True)\n",
    "        self.fc_spike = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(\n",
    "            slope=25), init_hidden=False, output=True)\n",
    "\n",
    "\n",
    "        # # # Connecting CNN outputs with Fully Connected layers for classification\n",
    "\n",
    "        # self.class_fc1 = nn.Linear(in_features=192*3*3, out_features=240)\n",
    "        # self.class_fc2 = nn.Linear(in_features=240, out_features=120)\n",
    "        # self.class_out = nn.Linear(in_features=120, out_features=10)\n",
    "\n",
    "        # self.fc_spike = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(\n",
    "        #     slope=25), init_hidden=False, output=True)\n",
    "\n",
    "        # Connecting CNN outputs with Fully Connected layers for bounding box\n",
    "        # self.box_fc1 = nn.Linear(in_features=192*3*3, out_features=240)\n",
    "        # self.box_fc2 = nn.Linear(in_features=240, out_features=120)\n",
    "        # self.box_out = nn.Linear(in_features=120, out_features=4)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        mem4 = self.lif4.init_leaky()\n",
    "        mem5 = self.lif5.init_leaky()\n",
    "\n",
    "        mem_fc_spike = self.fc_spike.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk5_rec = []\n",
    "        mem5_rec = []\n",
    "\n",
    "        for k in range(self.timesteps):\n",
    "            t = inputs[k, :, :, :]\n",
    "            # t = inputs\n",
    "            t = self.conv1(t)\n",
    "            t = F.max_pool2d(t, kernel_size=2)\n",
    "            t, mem1 = self.lif1(t, mem1)\n",
    "\n",
    "            t = self.conv2(t)\n",
    "            t = F.max_pool2d(t, kernel_size=2,)\n",
    "            t, mem2 = self.lif2(t, mem2)\n",
    "\n",
    "\n",
    "            t = self.conv3(t)\n",
    "            t = F.max_pool2d(t, kernel_size=2)\n",
    "            t, mem3 = self.lif3(t, mem3)\n",
    "\n",
    "\n",
    "            t = self.conv4(t)\n",
    "            t = F.max_pool2d(t, kernel_size=2)\n",
    "            t, mem4 = self.lif4(t, mem4)\n",
    "\n",
    "\n",
    "            t = self.conv5(t)\n",
    "            class_t, mem5 = self.lif5(t, mem5)\n",
    "            # t = F.relu(t)\n",
    "            # t = F.avg_pool2d(t, 1)\n",
    "\n",
    "            class_t = self.avg_pool(class_t)\n",
    "            # t = torch.flatten(t,start_dim=1)\n",
    "\n",
    "            class_t = self.flat(class_t)\n",
    "            class_t = self.dropout(class_t)\n",
    "            class_t = class_t.T\n",
    "            class_t = self.fc(class_t)\n",
    "            class_t, mem_fc_spike = self.fc_spike(class_t, mem_fc_spike)\n",
    "            spk5_rec.append(class_t)\n",
    "            mem5_rec.append(mem_fc_spike)\n",
    "\n",
    "            # classifier\n",
    "            # class_t = self.class_fc1(t)\n",
    "            # class_t = F.relu(class_t)\n",
    "\n",
    "            # class_t = self.class_fc2(class_t)\n",
    "            # class_t = F.relu(class_t)\n",
    "\n",
    "\n",
    "            # class_t, mem_fc_spike = self.fc_spike(class_t, mem_fc_spike)\n",
    "\n",
    "\n",
    "\n",
    "            # box_t = self.box_fc1(t)\n",
    "            # box_t = F.relu(box_t)\n",
    "\n",
    "            # box_t = self.box_fc2(box_t)\n",
    "            # box_t = F.relu(box_t)\n",
    "\n",
    "            # box_t = self.box_out(box_t)\n",
    "            # box_t = F.sigmoid(box_t)\n",
    "\n",
    "        return torch.stack(spk5_rec, dim=0), torch.stack(mem5_rec, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(3, 10, 8)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(net, num_steps, data):\n",
    "  mem_rec = []\n",
    "  spk_rec = []\n",
    "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "  for step in range(num_steps):\n",
    "      spk_out, mem_out = net(data)\n",
    "      spk_rec.append(spk_out)\n",
    "      mem_rec.append(mem_out)\n",
    "\n",
    "  return torch.stack(spk_rec), torch.stack(mem_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(train_loader, net, num_steps):\n",
    "  with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    net.eval()\n",
    "\n",
    "    # train_loader = iter(train_loader)\n",
    "    for batch, (images, annotations) in tqdm(enumerate(train_loader)):\n",
    "      imgs = list(img.to(device) for img in images)\n",
    "      neural_images = torch.stack(imgs)\n",
    "      x = neural_images.to(device)\n",
    "      annotations = [{k: v for k, v in t.items()} for t in annotations]\n",
    "      y = annotations[0]['labels'].to(device)\n",
    "      z = annotations[0]['boxes'].to(device)\n",
    "      print(len(y))\n",
    "      try:\n",
    "        spk_rec, _ = forward_pass(net, num_steps, x)\n",
    "\n",
    "        acc += SF.accuracy_rate(spk_rec[0], y[0]) * spk_rec.size(1)\n",
    "        total += spk_rec.size(1)\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:04,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:05,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:05,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:06,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:06,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:07,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:08,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:08,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:09,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:10,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:10,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:11,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:12,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:12,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:13,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:13,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:14,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:15,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:15,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:16,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:16,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:17,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:18,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [00:18,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:19,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:20,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:20,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:21,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:21,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "test_acc = batch_accuracy(valid_dl, model, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total accuracy on the test set is: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_rec, mem_rec = forward_pass(model, num_steps, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ = model(data.view(batch_size, -1))\n",
    "    _, idx = output.sum(dim=0).max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer():\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 5, 5, 5], device='cuda:0')\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([8, 1, 10])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for dimension 0 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000015?line=28'>29</a>\u001b[0m \u001b[39m# sum loss at every step\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000015?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_steps):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000015?line=30'>31</a>\u001b[0m   loss_val \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss(mem_rec[step], targets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000015?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining loss: \u001b[39m\u001b[39m{\u001b[39;00mloss_val\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000015?line=34'>35</a>\u001b[0m print_batch_accuracy(data, targets, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for dimension 0 with size 8"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "for batch, (images, annotations) in tqdm(enumerate(train_dl)):\n",
    "  imgs = list(img.to(device) for img in images)\n",
    "  neural_images = torch.stack(imgs)\n",
    "  x = neural_images.to(device)\n",
    "  annotations = [{k: v for k, v in t.items()} for t in annotations]\n",
    "  y = annotations[0]['labels'].to(device)\n",
    "  z = annotations[0]['boxes'].to(device)\n",
    "  data = x\n",
    "  targets = y\n",
    "  print(targets)\n",
    "  if batch == 1:\n",
    "    break\n",
    "\n",
    "# data = data.to(device)\n",
    "# targets = targets.to(device)\n",
    "print(data.shape)\n",
    "\n",
    "spk_rec, mem_rec = model(data)\n",
    "print(mem_rec.size())\n",
    "\n",
    "# initialize the total loss value\n",
    "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "\n",
    "# sum loss at every step\n",
    "for step in range(num_steps):\n",
    "  loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "print(f\"Training loss: {loss_val.item():.3f}\")\n",
    "\n",
    "print_batch_accuracy(data, targets, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = SF.ce_rate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(train_loader, net, num_steps):\n",
    "  with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    net.eval()\n",
    "\n",
    "    train_loader = iter(train_loader)\n",
    "    for data, targets in train_loader:\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "      spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "\n",
    "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "      total += spk_rec.size(1)\n",
    "\n",
    "  return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    # Defining the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
    "    num_of_epochs = 10\n",
    "    epochs = []\n",
    "    losses = []\n",
    "    test_acc_hist = []\n",
    "    # Creating a directory for storing models\n",
    "\n",
    "    for epoch in range(num_of_epochs):\n",
    "        tot_loss = 0\n",
    "        tot_correct = 0\n",
    "        train_start = time.time()\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        for batch, (images, annotations) in tqdm(enumerate(train_dl)):\n",
    "\n",
    "        \t# Converting data from cpu to GPU if available to improve speed\n",
    "            imgs = list(img.to(device) for img in images)\n",
    "            neural_images = torch.stack(imgs)\n",
    "            x = neural_images.to(device)\n",
    "            annotations = [{k: v for k, v in t.items()} for t in annotations]\n",
    "            y = annotations[0]['labels'].to(device)\n",
    "            z = annotations[0]['boxes'].to(device)\n",
    "            avg_loss = backprop.BPTT(model, train_loader, optimizer=optimizer, criterion=loss_fn,\n",
    "                            num_steps=num_steps, time_var=False, device=device)\n",
    "            # Sets the gradients of all optimized tensors to zero\n",
    "            optimizer.zero_grad()\n",
    "            [y_pred,z_pred]= model(x)\n",
    "            # Compute loss (here CrossEntropyLoss)\n",
    "            class_loss = F.cross_entropy(y_pred, y)\n",
    "            box_loss = F.mse_loss(z_pred, z)\n",
    "            (box_loss + class_loss).backward()\n",
    "            # class_loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"Train batch:\", batch+1, \" epoch: \", epoch, \" \",\n",
    "                  (time.time()-train_start)/60, end='\\r')\n",
    "\n",
    "        model.eval()\n",
    "        for batch, (images, annotations) in tqdm(enumerate(valid_dl)):\n",
    "        \t# Converting data from cpu to GPU if available to improve speed\t\n",
    "            imgs = list(img.to(device) for img in images)\n",
    "            neural_images = torch.stack(imgs)\n",
    "            x = neural_images.to(device)\n",
    "            annotations = [{k: v for k, v in t.items()} for t in annotations]\n",
    "            y = annotations[0]['labels'].to(device)\n",
    "            z = annotations[0]['boxes'].to(device)\n",
    "            # Sets the gradients of all optimized tensors to zero\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                [y_pred,z_pred]= model(x)\n",
    "                \n",
    "                # Compute loss (here CrossEntropyLoss)\n",
    "                class_loss = F.cross_entropy(y_pred, y)\n",
    "                box_loss = F.mse_loss(z_pred, z)\n",
    "                # Compute loss (here CrossEntropyLoss)\n",
    "\n",
    "            tot_loss += (class_loss.item() + box_loss.item())\n",
    "            tot_correct += get_num_correct(y_pred, y)\n",
    "            print(\"Test batch:\", batch+1, \" epoch: \", epoch, \" \",\n",
    "                  (time.time()-train_start)/60, end='\\r')\n",
    "        epochs.append(epoch)\n",
    "        losses.append(tot_loss)\n",
    "        print(\"Epoch\", epoch, \"Accuracy\", (tot_correct)/2.4, \"loss:\",\n",
    "              tot_loss, \" time: \", (time.time()-train_start)/60, \" mins\")\n",
    "        torch.save(model.state_dict(), \"model_ep\"+str(epoch+1)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (256x1x1). Calculated output size: (256x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000031?line=0'>1</a>\u001b[0m train(model)\n",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb Cell 9'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=24'>25</a>\u001b[0m \u001b[39m# Sets the gradients of all optimized tensors to zero\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=25'>26</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=26'>27</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=27'>28</a>\u001b[0m \u001b[39m# print(y_pred)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=28'>29</a>\u001b[0m \u001b[39m# Compute loss (here CrossEntropyLoss)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=29'>30</a>\u001b[0m class_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(y_pred[\u001b[39m0\u001b[39m], y[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb Cell 7'\u001b[0m in \u001b[0;36mNetwork.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=96'>97</a>\u001b[0m t, mem3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlif1(t, mem3)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=99'>100</a>\u001b[0m t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4(t)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=100'>101</a>\u001b[0m t \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmax_pool2d(t, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=101'>102</a>\u001b[0m t, mem4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlif1(t, mem4)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=104'>105</a>\u001b[0m t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv5(t)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_jit_internal.py:422\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_jit_internal.py?line=419'>420</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_jit_internal.py?line=420'>421</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_jit_internal.py?line=421'>422</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:797\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py?line=794'>795</a>\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py?line=795'>796</a>\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py?line=796'>797</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (256x1x1). Calculated output size: (256x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b62d0206b570d77ef1bfa49bb04057592ebbd6080402d9290ba5af22960e1b27"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
