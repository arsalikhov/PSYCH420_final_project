{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import MyOwnDataloader\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total    : 12636.061696\n",
      "free     : 11491.868672\n",
      "used     : 1144.193024\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "\n",
    "from pynvml import *\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total/1000000}')\n",
    "print(f'free     : {info.free/1000000}')\n",
    "print(f'used     : {info.used/1000000}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=8.80s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=9.36s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataDir='/media/gamedisk/COCO_dataset/'\n",
    "val='val2017'\n",
    "train = 'train2017'\n",
    "\n",
    "val_annFile='{}/annotations/instances_{}.json'.format(dataDir,val)\n",
    "train_annFile='{}/annotations/instances_{}.json'.format(dataDir,train) \n",
    "# Batch size\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "\n",
    "classes = {\n",
    "    \"bird\": 1,\n",
    "    \"cat\": 2,\n",
    "    \"dog\": 3,\n",
    "    \"horse\": 4,\n",
    "    \"sheep\": 5,\n",
    "    \"cow\": 6,\n",
    "    \"elephant\": 7,\n",
    "    \"bear\": 8,\n",
    "    \"zebra\": 9,\n",
    "    \"giraffe\": 10\n",
    "}\n",
    "\n",
    "\n",
    "coco = COCO(val_annFile)\n",
    "val_loader = MyOwnDataloader(dataDir = dataDir, dataType = val,\n",
    "                     annFile = val_annFile, classes = classes, train_batch_size=batch_size)\n",
    "valid_dl = val_loader.concat_datasets()\n",
    "\n",
    "\n",
    "coco = COCO(train_annFile)\n",
    "train_loader = MyOwnDataloader(dataDir = dataDir, dataType = train,\n",
    "                     annFile = train_annFile, classes = classes, train_batch_size=batch_size)\n",
    "train_dl = val_loader.concat_datasets()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "num_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, timesteps: int):\n",
    "        super(Network, self).__init__()\n",
    "        self.timesteps = timesteps\n",
    "        # CNNs for rgb images\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32,\n",
    "                        kernel_size=7,\n",
    "                        padding=3,\n",
    "                        # no bias because it is not bio-plausible (and hard to impl in neuromorphic hardware)\n",
    "                        bias=True,\n",
    "                        dilation=1,\n",
    "                        stride=2)\n",
    "        self.lif1 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64,\n",
    "                               kernel_size=3,\n",
    "                               padding=1,\n",
    "                               # no bias because it is not bio-plausible (and hard to impl in neuromorphic hardware)\n",
    "                               bias=True,\n",
    "                               stride=2)\n",
    "        self.lif2 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                        bias=True,\n",
    "                        stride=2)\n",
    "        self.lif3 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                        # no bias because it is not bio-plausible (and hard to impl in neuromorphic hardware)\n",
    "                        bias=True,\n",
    "                        stride=2)\n",
    "        self.lif4 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 512,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    bias=True,\n",
    "                    stride=2)\n",
    "        self.lif5 = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(slope=25), init_hidden=False)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc = nn.Linear(512, out_channels, bias=True)\n",
    "        self.fc_spike = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(\n",
    "            slope=25), init_hidden=False, output=True)\n",
    "\n",
    "\n",
    "        # # # Connecting CNN outputs with Fully Connected layers for classification\n",
    "\n",
    "        # self.class_fc1 = nn.Linear(in_features=192*3*3, out_features=240)\n",
    "        # self.class_fc2 = nn.Linear(in_features=240, out_features=120)\n",
    "        # self.class_out = nn.Linear(in_features=120, out_features=10)\n",
    "\n",
    "        self.fc_spike = snn.Leaky(beta=0.5, spike_grad=surrogate.fast_sigmoid(\n",
    "            slope=25), init_hidden=False, output=True)\n",
    "\n",
    "        # Connecting CNN outputs with Fully Connected layers for bounding box\n",
    "        # self.box_fc1 = nn.Linear(in_features=192*3*3, out_features=240)\n",
    "        # self.box_fc2 = nn.Linear(in_features=240, out_features=120)\n",
    "        # self.box_out = nn.Linear(in_features=120, out_features=4)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        mem4 = self.lif4.init_leaky()\n",
    "        mem5 = self.lif5.init_leaky()\n",
    "\n",
    "        mem_fc_spike = self.fc_spike.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk5_rec = []\n",
    "        mem5_rec = []\n",
    "\n",
    "        for k in range(self.timesteps):\n",
    "            t = inputs[k, :, :, :]\n",
    "            # t = inputs\n",
    "            t = self.conv1(t)\n",
    "            t = F.max_pool2d(t, kernel_size=2)\n",
    "            t, mem1 = self.lif1(t, mem1)\n",
    "\n",
    "            t = self.conv2(t)\n",
    "            t = F.max_pool2d(t, kernel_size=2,)\n",
    "            t, mem2 = self.lif1(t, mem2)\n",
    "\n",
    "\n",
    "            t = self.conv3(t)\n",
    "            t = F.max_pool2d(t, kernel_size=2)\n",
    "            t, mem3 = self.lif1(t, mem3)\n",
    "\n",
    "\n",
    "            t = self.conv4(t)\n",
    "            t = F.max_pool2d(t, kernel_size=2)\n",
    "            t, mem4 = self.lif1(t, mem4)\n",
    "\n",
    "\n",
    "            t = self.conv5(t)\n",
    "            # t, mem5 = self.lif1(t, mem5)\n",
    "            t = F.relu(t)\n",
    "            t = F.avg_pool2d(t, 1)\n",
    "\n",
    "            # t = self.avg_pool(t)\n",
    "            t = torch.flatten(t,start_dim=1)\n",
    "\n",
    "\n",
    "            # classifier\n",
    "            # class_t = self.class_fc1(t)\n",
    "            # class_t = F.relu(class_t)\n",
    "\n",
    "            # class_t = self.class_fc2(class_t)\n",
    "            # class_t = F.relu(class_t)\n",
    "\n",
    "\n",
    "            # class_t, mem_fc_spike = self.fc_spike(class_t, mem_fc_spike)\n",
    "\n",
    "            class_t = self.flat(t)\n",
    "            class_t = self.dropout(class_t)\n",
    "            class_t = class_t.T\n",
    "            class_t = self.fc(class_t)\n",
    "            class_t, mem_fc_spike = self.fc_spike(class_t, mem_fc_spike)\n",
    "\n",
    "\n",
    "            # box_t = self.box_fc1(t)\n",
    "            # box_t = F.relu(box_t)\n",
    "\n",
    "            # box_t = self.box_fc2(box_t)\n",
    "            # box_t = F.relu(box_t)\n",
    "\n",
    "            # box_t = self.box_out(box_t)\n",
    "            # box_t = F.sigmoid(box_t)\n",
    "\n",
    "        return class_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return torch.round(preds).argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    # Defining the optimizer\n",
    "    optimizer = optim.SGD(model.parameters(),lr = 0.1)\n",
    "    num_of_epochs = 10\n",
    "    epochs = []\n",
    "    losses = []\n",
    "    # Creating a directory for storing models\n",
    "\n",
    "    for epoch in range(num_of_epochs):\n",
    "        tot_loss = 0\n",
    "        tot_correct = 0\n",
    "        train_start = time.time()\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        for batch, (images, annotations) in tqdm(enumerate(train_dl)):\n",
    "\n",
    "        \t# Converting data from cpu to GPU if available to improve speed\n",
    "            imgs = list(img.to(device) for img in images)\n",
    "            neural_images = torch.stack(imgs)\n",
    "            x = neural_images.to(device)\n",
    "            annotations = [{k: v for k, v in t.items()} for t in annotations]\n",
    "            y = annotations[0]['labels'].to(device)\n",
    "            z = annotations[0]['boxes'].to(device)\n",
    "            # Sets the gradients of all optimized tensors to zero\n",
    "            optimizer.zero_grad()\n",
    "            [y_pred,z_pred]= model(x)\n",
    "            # Compute loss (here CrossEntropyLoss)\n",
    "            class_loss = F.cross_entropy(y_pred, y)\n",
    "            box_loss = F.mse_loss(z_pred, z)\n",
    "            (box_loss + class_loss).backward()\n",
    "            # class_loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"Train batch:\", batch+1, \" epoch: \", epoch, \" \",\n",
    "                  (time.time()-train_start)/60, end='\\r')\n",
    "\n",
    "        model.eval()\n",
    "        for batch, (images, annotations) in tqdm(enumerate(valid_dl)):\n",
    "        \t# Converting data from cpu to GPU if available to improve speed\t\n",
    "            imgs = list(img.to(device) for img in images)\n",
    "            neural_images = torch.stack(imgs)\n",
    "            x = neural_images.to(device)\n",
    "            annotations = [{k: v for k, v in t.items()} for t in annotations]\n",
    "            y = annotations[0]['labels'].to(device)\n",
    "            z = annotations[0]['boxes'].to(device)\n",
    "            # Sets the gradients of all optimized tensors to zero\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                [y_pred,z_pred]= model(x)\n",
    "                \n",
    "                # Compute loss (here CrossEntropyLoss)\n",
    "                class_loss = F.cross_entropy(y_pred, y)\n",
    "                box_loss = F.mse_loss(z_pred, z)\n",
    "                # Compute loss (here CrossEntropyLoss)\n",
    "\n",
    "            tot_loss += (class_loss.item() + box_loss.item())\n",
    "            tot_correct += get_num_correct(y_pred, y)\n",
    "            print(\"Test batch:\", batch+1, \" epoch: \", epoch, \" \",\n",
    "                  (time.time()-train_start)/60, end='\\r')\n",
    "        epochs.append(epoch)\n",
    "        losses.append(tot_loss)\n",
    "        print(\"Epoch\", epoch, \"Accuracy\", (tot_correct)/2.4, \"loss:\",\n",
    "              tot_loss, \" time: \", (time.time()-train_start)/60, \" mins\")\n",
    "        torch.save(model.state_dict(), \"model_ep\"+str(epoch+1)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (lif1): Leaky()\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (lif2): Leaky()\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (lif3): Leaky()\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (lif4): Leaky()\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (lif5): Leaky()\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (fc_spike): Leaky()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network(3, 10, 8)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (256x1x1). Calculated output size: (256x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000031?line=0'>1</a>\u001b[0m train(model)\n",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb Cell 9'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=24'>25</a>\u001b[0m \u001b[39m# Sets the gradients of all optimized tensors to zero\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=25'>26</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=26'>27</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=27'>28</a>\u001b[0m \u001b[39m# print(y_pred)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=28'>29</a>\u001b[0m \u001b[39m# Compute loss (here CrossEntropyLoss)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000021?line=29'>30</a>\u001b[0m class_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(y_pred[\u001b[39m0\u001b[39m], y[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb Cell 7'\u001b[0m in \u001b[0;36mNetwork.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=96'>97</a>\u001b[0m t, mem3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlif1(t, mem3)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=99'>100</a>\u001b[0m t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4(t)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=100'>101</a>\u001b[0m t \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmax_pool2d(t, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=101'>102</a>\u001b[0m t, mem4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlif1(t, mem4)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/arsalikhov/Documents/PSYCH420_final_project/code/model.ipynb#ch0000027?line=104'>105</a>\u001b[0m t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv5(t)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_jit_internal.py:422\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_jit_internal.py?line=419'>420</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_jit_internal.py?line=420'>421</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/_jit_internal.py?line=421'>422</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:797\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py?line=794'>795</a>\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py?line=795'>796</a>\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> <a href='file:///home/arsalikhov/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py?line=796'>797</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (256x1x1). Calculated output size: (256x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b62d0206b570d77ef1bfa49bb04057592ebbd6080402d9290ba5af22960e1b27"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
